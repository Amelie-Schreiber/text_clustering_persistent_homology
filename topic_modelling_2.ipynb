{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling with Persistent Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy matplotlib scikit-learn gudhi pot -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = [\"Deep learning is a subfield of machine learning that's based on artificial neural networks with representation learning. It allows computational models composed of multiple layers to learn and represent data with multiple levels of abstraction, mimicking the human brain, thereby helping to decipher patterns and structures in data. Deep learning techniques have been widely applied in several industries and fields such as healthcare, finance, transportation, and more, offering solutions for image and speech recognition, natural language processing, and various other complex tasks.\", \n",
    "          \n",
    "          \"The power of deep learning lies in its ability to automatically extract features from raw data. Traditional machine learning models require manual feature engineering, where the relevant features are extracted before applying the model. However, with deep learning, the model learns these features itself from the data, which reduces the need for human intervention. This aspect of deep learning has made it an integral part of many modern artificial intelligence systems.\", \n",
    "          \n",
    "          \"Deep learning models are often built using a layered architecture where each layer learns to transform its input data into a slightly more abstract and composite representation. These layers are interconnected through nodes, or neurons, with each node in a layer connecting to each node in the next layer. The depth of these layers is where deep learning gets its name - 'deep' refers to the number of layers through which the data is transformed.\", \n",
    "          \n",
    "          \"While deep learning has brought significant advancements, it is also accompanied by certain challenges. These include the need for large amounts of data to train models, the extensive computational power required, and the lack of transparency or interpretability of the models. Despite these challenges, the potential benefits that deep learning can bring to various fields make it an area of intense research and development.\", \n",
    "\n",
    "          \"Deep learning methods have exhibited remarkable success in a plethora of areas and are being increasingly used in the critical domain of healthcare. They are employed for a variety of tasks including disease detection, personalized treatment, drug discovery, and patient care. For instance, convolutional neural networks (CNNs) have shown promise in medical imaging analysis, helping doctors to identify diseases such as cancer at an early stage. Furthermore, recurrent neural networks (RNNs) are utilized in electronic health record data analysis, providing insightful information about patients' health trends and future risks.\",\n",
    "\n",
    "          \"A pivotal aspect of deep learning is the concept of representation learning. Unlike traditional machine learning methods that rely on manually engineered features, deep learning algorithms are capable of learning useful features directly from raw data. This is particularly useful in complex domains such as natural language processing, image recognition, and speech recognition, where the design of suitable features can be challenging and time-consuming. By automatically learning these representations, deep learning can achieve state-of-the-art performance on a variety of tasks.\", \n",
    "\n",
    "          \"Deep learning models, like artificial neural networks, are designed to simulate the way the human brain analyzes and processes information. These models are composed of multiple layers of artificial neurons or nodes, each of which can process inputs, apply a set of functions, and pass the result to the next layer. This hierarchical structure allows deep learning models to handle complex tasks by breaking them down into simpler, manageable sub-tasks. This capability has led to breakthroughs in various fields, from computer vision to natural language understanding.\", \n",
    "\n",
    "          \"A compelling advantage of deep learning is its ability to process and generate meaningful information from big data. As the amount of data generated by various sources such as social media, sensors, and IoT devices continues to grow, the need for advanced tools to analyze this data becomes more significant. Deep learning, with its ability to learn from vast amounts of data and generate accurate predictions, is perfectly suited for this task. It has found applications in areas such as predictive maintenance, fraud detection, and customer behavior analysis.\", \n",
    "\n",
    "          \"Despite the numerous successes of deep learning, it is essential to mention its challenges and areas for improvement. One of the key issues is the requirement for large amounts of labeled data to train the models effectively. Obtaining this data can be expensive and time-consuming. Moreover, deep learning models are often criticized for their lack of interpretability; they are frequently referred to as black boxes due to their complex internal workings. Research is being conducted to develop methods for better understanding and visualizing these models, which will not only enhance trust in their predictions but also improve their overall performance.\", \n",
    "                    \n",
    "          \"Deep learning, a subset of machine learning, is a method that is based on artificial neural networks with representation learning. Representation learning can automatically discover the representations needed for feature detection or classification from raw data. This replaces the manual feature engineering used in traditional machine learning. Deep learning models are loosely related to information processing and communication patterns in a biological nervous system, such as neural coding that attempts to define a relationship between various stimuli and associated neuronal responses in the brain.\", \n",
    "          \n",
    "          \"Convolutional Neural Networks (CNNs) are a class of deep learning algorithms that have proven extremely effective for analyzing visual imagery. They are designed to automatically and adaptively learn spatial hierarchies of features from tasks with only minimal pre-processing. They have been applied to fields including bioinformatics, drug design, medical image analysis, natural language processing, and even in the process of creating art.\", \n",
    "\n",
    "          \"Recurrent Neural Networks (RNNs) are another class of deep learning models, and they excel at handling sequential data. Unlike feedforward neural networks, RNNs have a form of internal memory that allows them to remember previous inputs in the sequence. This unique feature of RNNs makes them particularly well-suited for tasks like language modeling, translation, and speech recognition.\", \n",
    "\n",
    "          \"Another exciting area in deep learning is the use of Generative Adversarial Networks (GANs). GANs are a class of artificial intelligence algorithms used in unsupervised machine learning, implementing two neural networks contesting with each other in a game. One network, the generator, generates new data instances, while the other, the discriminator, evaluates them for authenticity. The generator improves its ability to generate more realistic data, and the discriminator enhances its ability to distinguish real data from the artificially generated ones. This dynamic creates a powerful tool for generating synthetic data.\",\n",
    "          \n",
    "          \"Deep learning, a subset of machine learning, has revolutionized the field of artificial intelligence by enabling computers to learn and make decisions in a manner similar to humans. At the heart of deep learning are neural networks, computational models inspired by the structure and function of the human brain. These networks consist of interconnected nodes, or artificial neurons, organized in layers. Each layer extracts and transforms information before passing it on to the next layer, gradually learning to recognize patterns and make accurate predictions. Through a process called training, neural networks adjust their parameters based on labeled data, optimizing their ability to perform tasks such as image recognition, natural language processing, and voice synthesis.\",\n",
    "\n",
    "          \"Neural networks are known for their ability to handle complex and high-dimensional data, making them highly effective in fields such as computer vision and speech recognition. Convolutional neural networks (CNNs), a type of neural network widely used in computer vision tasks, are designed to recognize visual patterns and features by applying filters to input images. Recurrent neural networks (RNNs), on the other hand, are particularly suited for sequential data analysis, such as natural language processing and time series prediction. With their ability to retain information from previous steps, RNNs excel at capturing context and dependencies in sequential data.\",\n",
    "\n",
    "          \"One of the key advantages of deep learning and neural networks is their ability to learn hierarchical representations of data. In deep neural networks, multiple layers learn increasingly abstract and complex features, allowing the model to capture intricate patterns that may be difficult to define explicitly. This hierarchical learning enables neural networks to automatically extract relevant features from raw data, reducing the need for manual feature engineering, which can be time-consuming and challenging. Instead, deep learning models can autonomously discover meaningful representations from the data, resulting in more accurate and adaptable systems.\",\n",
    "\n",
    "          \"While deep learning and neural networks have achieved remarkable success in various domains, they also pose challenges. Training deep neural networks typically requires large amounts of labeled data, which can be expensive and time-consuming to obtain. Additionally, training deep models can be computationally intensive, requiring significant computational resources and time. To address these challenges, researchers have explored techniques such as transfer learning, which leverages pre-trained models on large datasets to boost performance on smaller, specialized tasks. Furthermore, advancements in hardware, such as graphics processing units (GPUs) and specialized accelerators like tensor processing units (TPUs), have significantly accelerated training and inference in neural networks.\",\n",
    "\n",
    "          \"The future of deep learning and neural networks holds great promise. Ongoing research focuses on developing more efficient and interpretable architectures, improving generalization capabilities, and addressing issues related to robustness, fairness, and transparency. Additionally, efforts are being made to integrate deep learning with other branches of AI, such as reinforcement learning, to create even more powerful and versatile systems. As the field continues to evolve, deep learning and neural networks are likely to play a crucial role in driving advancements across a wide range of industries, from healthcare and finance to transportation and beyond.\",\n",
    "          \n",
    "          \n",
    "          \n",
    "          \"Let's consider the topic of sustainable agriculture. This practice refers to the production of food, fiber, or other plant or animal products using farming techniques that protect the environment, public health, human communities, and animal welfare. It equires a deep understanding of natural processes. This field is focused on long-term solutions that aim to balance current needs with the future availability of natural resources. Sustainable agriculture techniques may include crop rotation, biological pest control, and the reduction of chemical fertilizers and pesticides.\", \n",
    "          \n",
    "          \"The color blue is often associated with feelings of calmness and serenity. It's the hue of the clear sky and the deep sea, and in the world of art, it's a color that's been used to great effect by painters like Vincent van Gogh and Pablo Picasso. According to color psychology, blue can also symbolize trust, loyalty, and wisdom. In the natural world, blue is less common among plants and animals, which may be why we find it so striking when we see a blue flower or bird.\",\n",
    "          \n",
    "          \"In recent years, modern healthcare has witnessed remarkable advancements, transforming the way medical professionals diagnose, treat, and prevent diseases. Technological innovations have revolutionized the field, leading to more accurate diagnoses through advanced imaging techniques such as MRI and CT scans. Moreover, robotic surgeries have enabled surgeons to perform complex procedures with enhanced precision and reduced invasiveness. The advent of electronic health records (EHRs) has streamlined patient information management, improving coordination among healthcare providers. Telemedicine has gained significant traction, allowing patients to consult with doctors remotely, ensuring accessible healthcare, especially in rural areas. Artificial intelligence and machine learning are also making strides in healthcare, facilitating early disease detection and personalized treatment plans.\", \n",
    "          \n",
    "          \"Skiing is a popular winter sport that combines adventure, athleticism, and the joy of being in the great outdoors. Skiers glide down snow-covered slopes, equipped with skis, boots, and poles, providing them with balance and control. From the beginner's gentle slopes to the adrenaline-pumping black diamond trails, skiing offers something for everyone. Ski resorts around the world provide a range of amenities, including ski lifts, ski schools, and rental equipment, catering to skiers of all levels. The sport also promotes physical fitness, strengthening the leg muscles, improving cardiovascular health, and enhancing overall coordination. Additionally, skiing can be a social activity, as friends and families come together to enjoy the slopes and embrace the breathtaking beauty of snow-capped mountains.\",\n",
    "\n",
    "          \"Zombies have captivated popular culture, appearing in numerous books, movies, and TV shows. These fictional creatures, often portrayed as reanimated corpses, evoke a sense of fear and fascination. Originating from Haitian folklore, zombies gained prominence through George A. Romero's classic film Night of the Living Dead. Zombies are typically depicted as mindless, ravenous beings with an insatiable hunger for human flesh. They symbolize various societal fears, such as the collapse of civilization, infectious diseases, and the loss of individuality. While their nature varies across different media, the relentless pursuit of survivors and the struggle for survival remain common themes. Zombies have become a popular trope in the horror genre, providing a thrilling and often thought-provoking exploration of human nature and our ability to endure in the face of adversity.\",\n",
    "\n",
    "          \"The concept of alien invasions has long fascinated humanity, sparking our imagination about the existence of extraterrestrial life and their potential encounters with Earth. Countless science fiction stories, movies, and games have explored the theme of alien invasions, presenting scenarios ranging from peaceful first contact to hostile takeovers. These narratives often delve into questions about humanity's resilience, resourcefulness, and ability to unite against a common threat. Alien invasions serve as a metaphor for human anxieties, exploring themes such as the fear of the unknown, the fragility of our existence, and the consequences of our actions. They also encourage contemplation about our place in the universe and the potential for interstellar exploration and cooperation.\",\n",
    "\n",
    "          \"Comic books have been a beloved form of entertainment for decades, offering a unique blend of visual art and storytelling. These colorful narratives feature superheroes, villains, and everyday people navigating extraordinary worlds and grappling with complex moral dilemmas. Comic book characters such as Superman, Batman, and Spider-Man have become cultural icons, inspiring generations with their tales of heroism and personal growth. The medium allows for diverse storytelling styles, ranging from action-packed adventures to introspective dramas. With their blend of captivating visuals and compelling narratives, comic books transcend age boundaries, appealing to both children and adults alike. They have also served as the source material for blockbuster movies and TV series, further cementing their cultural significance.\"\n",
    "          \n",
    "          ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudhi.wasserstein.barycenter import lagrangian_barycenter\n",
    "import numpy as np\n",
    "import gudhi\n",
    "from gudhi.wasserstein.barycenter import lagrangian_barycenter as bary\n",
    "from gudhi.persistence_graphical_tools import plot_persistence_diagram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import DistilBertConfig, DistilBertModel\n",
    "from scipy.spatial import distance_matrix\n",
    "import gudhi as gd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_output(sentence, layer, head):\n",
    "    # Load pre-trained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "    model = AutoModel.from_pretrained(\"xlm-roberta-base\") \n",
    "\n",
    "\n",
    "    # Tokenize input and convert to tensor\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    # Forward pass\n",
    "    # Specify `output_hidden_states=True` when calling the model\n",
    "    outputs = model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "    # Obtain the attention weights\n",
    "    attentions = outputs.attentions\n",
    "\n",
    "    # Obtain the attention weights for the specific layer and head\n",
    "    S = attentions[layer][0, head]\n",
    "\n",
    "    # Obtain the value vectors\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden_states = outputs.hidden_states[layer]\n",
    "        all_W_v = model.encoder.layer[layer].attention.self.value.weight\n",
    "        num_heads = model.config.num_attention_heads\n",
    "        head_dim = model.config.hidden_size // num_heads\n",
    "        W_v_heads = all_W_v.view(num_heads, head_dim, model.config.hidden_size)\n",
    "        W_v = W_v_heads[head]\n",
    "        V = torch.matmul(hidden_states, W_v.t())\n",
    "\n",
    "    # Compute the output O\n",
    "    O = torch.matmul(S, V)\n",
    "\n",
    "    return O\n",
    "\n",
    "\n",
    "\n",
    "def compute_phrase_distances_and_homology(context_vectors, sentence, phrase):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "    # Tokenize the sentence and the phrase\n",
    "    sentence_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "    phrase_tokens = tokenizer.encode(phrase, add_special_tokens=False)\n",
    "\n",
    "    # Find the indices of the phrase tokens in the sentence\n",
    "    phrase_indices = []\n",
    "    phrase_length = len(phrase_tokens)\n",
    "    for i in range(len(sentence_tokens) - phrase_length + 1):\n",
    "        if sentence_tokens[i:i+phrase_length] == phrase_tokens:\n",
    "            phrase_indices.extend(range(i, i+phrase_length))\n",
    "            break\n",
    "\n",
    "    # Extract the context vectors for the phrase\n",
    "    phrase_context_vectors = context_vectors[0, phrase_indices]\n",
    "\n",
    "    # Detach the tensor and convert to numpy array\n",
    "    phrase_context_vectors_np = phrase_context_vectors.detach().numpy()\n",
    "\n",
    "    # Compute the pairwise Euclidean distances among the phrase context vectors\n",
    "    distances = distance_matrix(phrase_context_vectors_np, phrase_context_vectors_np)\n",
    "\n",
    "    # Compute the persistent homology of the distance matrix\n",
    "    rips_complex = gd.RipsComplex(distance_matrix=distances, max_edge_length=np.max(distances))\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    persistent_homology = simplex_tree.persistence(min_persistence=0.001)\n",
    "\n",
    "    return persistent_homology\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Set the layer and head to use for computation\n",
    "layer = 11\n",
    "head = 7\n",
    "\n",
    "# Compute the context vectors for each text in the corpus\n",
    "context_1 = [compute_output(t, layer, head) for t in text_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1 = [compute_phrase_distances_and_homology(context_1[i], text_1[i], text_1[i]) for i in range(len(text_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from scipy.spatial.distance import squareform\n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a list to store the pairwise Wasserstein distances\n",
    "w_distances1 = []\n",
    "\n",
    "# Choose homology group's dimension\n",
    "dimension = 0\n",
    "\n",
    "# Compute the pairwise Wasserstein distances\n",
    "for i in range(len(diag1)):\n",
    "    for j in range(i+1, len(diag1)):\n",
    "        # Convert the persistence diagrams to numpy arrays\n",
    "        # Only keep the birth and death times\n",
    "        pd1 = np.array([point[1] for point in diag1[i] if point[0]==dimension])\n",
    "        pd2 = np.array([point[1] for point in diag1[j] if point[0]==dimension])\n",
    "\n",
    "        # Compute the Wasserstein distance\n",
    "        distance = wasserstein_distance(pd1, pd2)\n",
    "\n",
    "        # Add the distance to the list\n",
    "        w_distances1.append(distance)\n",
    "\n",
    "# Convert the list of distances to a symmetric matrix\n",
    "w_distances1 = squareform(w_distances1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 3.17150234, 3.26024125, 3.17146221, 3.22458193,\n",
       "        3.23343696, 2.83474395, 2.2357693 , 2.83389919, 3.16601845,\n",
       "        3.52124012, 3.71037292, 2.51614257, 2.97201606, 2.91868226,\n",
       "        3.28519258, 4.53060713, 2.55189241, 2.38405222, 4.54995018,\n",
       "        4.92487018, 5.02535699, 4.34499544, 3.41165627, 3.84182357],\n",
       "       [3.17150234, 0.        , 2.41986595, 1.28093106, 2.90373807,\n",
       "        2.58378254, 2.37714163, 1.95052895, 2.61008771, 2.64138195,\n",
       "        1.84887457, 1.54176103, 2.44490908, 3.15162039, 3.58131212,\n",
       "        2.8486736 , 5.61115206, 1.94059619, 2.31923516, 3.7465587 ,\n",
       "        5.22903221, 5.11299009, 4.91248138, 3.35513206, 4.65245821],\n",
       "       [3.26024125, 2.41986595, 0.        , 2.28308441, 3.14354008,\n",
       "        2.68949923, 3.00594349, 2.88518969, 2.17039078, 3.01263486,\n",
       "        3.34515424, 2.49021467, 2.15422925, 3.35285913, 3.78303751,\n",
       "        2.40116563, 5.78579577, 2.83413483, 2.35659073, 3.7213022 ,\n",
       "        5.49904827, 5.1319327 , 4.08187083, 3.41134729, 4.84289023],\n",
       "       [3.17146221, 1.28093106, 2.28308441, 0.        , 3.00443923,\n",
       "        2.1959544 , 2.10281902, 2.22610387, 2.61140545, 2.43190381,\n",
       "        1.72700665, 1.38485427, 2.87617396, 3.23624909, 3.5373768 ,\n",
       "        2.30612767, 5.71054069, 1.98807518, 2.00529452, 3.61998805,\n",
       "        5.15388887, 4.96840533, 5.26402925, 3.09486398, 4.78761584],\n",
       "       [3.22458193, 2.90373807, 3.14354008, 3.00443923, 0.        ,\n",
       "        3.13666334, 3.17005737, 2.2863732 , 2.25380255, 3.41360658,\n",
       "        3.8386309 , 3.59268752, 3.05582809, 1.88846478, 1.85924241,\n",
       "        1.96835303, 3.44070659, 2.55607104, 2.4225358 , 2.55294467,\n",
       "        3.34448882, 3.92867952, 3.45158045, 2.38642706, 2.48838937],\n",
       "       [3.23343696, 2.58378254, 2.68949923, 2.1959544 , 3.13666334,\n",
       "        0.        , 1.73345427, 2.3164961 , 2.66909693, 1.23829164,\n",
       "        2.43007557, 2.27028668, 2.61201139, 3.48467062, 3.78497286,\n",
       "        1.80532546, 5.845894  , 2.52896819, 2.37901734, 3.91780199,\n",
       "        5.43000073, 5.08157785, 5.38670027, 3.42068878, 4.86265268],\n",
       "       [2.83474395, 2.37714163, 3.00594349, 2.10281902, 3.17005737,\n",
       "        1.73345427, 0.        , 2.03251072, 2.38569081, 1.82115907,\n",
       "        2.06396271, 2.17694267, 2.36777581, 2.86387826, 3.54781481,\n",
       "        2.31889506, 5.85914649, 1.89407985, 1.80042169, 3.66741108,\n",
       "        4.82681288, 4.74937021, 4.784221  , 2.75333249, 4.39665075],\n",
       "       [2.2357693 , 1.95052895, 2.88518969, 2.22610387, 2.2863732 ,\n",
       "        2.3164961 , 2.03251072, 0.        , 2.15251114, 2.442004  ,\n",
       "        2.83526145, 2.79169621, 2.4937282 , 2.50125292, 2.53648771,\n",
       "        2.33852495, 4.58786972, 1.7719952 , 2.37354751, 3.73261453,\n",
       "        4.65834003, 4.69140979, 4.19577073, 3.06744934, 3.46921998],\n",
       "       [2.83389919, 2.61008771, 2.17039078, 2.61140545, 2.25380255,\n",
       "        2.66909693, 2.38569081, 2.15251114, 0.        , 2.76223176,\n",
       "        3.48137126, 2.73019094, 1.75090632, 2.33483396, 2.76369284,\n",
       "        1.9021423 , 4.71316965, 1.69080486, 1.58961624, 2.67984836,\n",
       "        3.98118698, 3.75696449, 3.50633347, 2.25224204, 3.40722991],\n",
       "       [3.16601845, 2.64138195, 3.01263486, 2.43190381, 3.41360658,\n",
       "        1.23829164, 1.82115907, 2.442004  , 2.76223176, 0.        ,\n",
       "        1.91158113, 2.37946966, 2.44292151, 3.66706074, 3.89886928,\n",
       "        2.15557547, 6.10531952, 2.57593278, 2.6689337 , 4.41587277,\n",
       "        5.75135744, 5.34610657, 5.56163786, 3.64488037, 4.90298498],\n",
       "       [3.52124012, 1.84887457, 3.34515424, 1.72700665, 3.8386309 ,\n",
       "        2.43007557, 2.06396271, 2.83526145, 3.48137126, 1.91158113,\n",
       "        0.        , 1.8218372 , 2.89223645, 3.82114863, 4.31845757,\n",
       "        2.85888215, 6.46884262, 2.86321161, 2.96126085, 4.85849824,\n",
       "        6.17427612, 5.58981953, 6.01469345, 4.14273327, 5.62138364],\n",
       "       [3.71037292, 1.54176103, 2.49021467, 1.38485427, 3.59268752,\n",
       "        2.27028668, 2.17694267, 2.79169621, 2.73019094, 2.37946966,\n",
       "        1.8218372 , 0.        , 2.84052897, 3.93105183, 4.1637955 ,\n",
       "        2.76962721, 6.28160182, 2.46019847, 2.36607444, 3.81167772,\n",
       "        5.70362428, 5.41302524, 5.67290877, 3.43060074, 5.27425657],\n",
       "       [2.51614257, 2.44490908, 2.15422925, 2.87617396, 3.05582809,\n",
       "        2.61201139, 2.36777581, 2.4937282 , 1.75090632, 2.44292151,\n",
       "        2.89223645, 2.84052897, 0.        , 2.76899603, 3.54205194,\n",
       "        2.47992952, 5.17855075, 2.18540434, 2.14021226, 3.89008692,\n",
       "        4.83708098, 4.1387905 , 3.76838649, 2.78545831, 4.31348002],\n",
       "       [2.97201606, 3.15162039, 3.35285913, 3.23624909, 1.88846478,\n",
       "        3.48467062, 2.86387826, 2.50125292, 2.33483396, 3.66706074,\n",
       "        3.82114863, 3.93105183, 2.76899603, 0.        , 2.93586946,\n",
       "        2.51089116, 3.97927672, 2.41241642, 2.53639305, 3.61594564,\n",
       "        3.06120394, 2.62111697, 2.77096717, 1.38591266, 2.72583084],\n",
       "       [2.91868226, 3.58131212, 3.78303751, 3.5373768 , 1.85924241,\n",
       "        3.78497286, 3.54781481, 2.53648771, 2.76369284, 3.89886928,\n",
       "        4.31845757, 4.1637955 , 3.54205194, 2.93586946, 0.        ,\n",
       "        2.75762819, 2.86185049, 2.67645184, 2.59226331, 2.97753829,\n",
       "        3.84437606, 5.07742377, 4.01357743, 3.28375677, 2.20057762],\n",
       "       [3.28519258, 2.8486736 , 2.40116563, 2.30612767, 1.96835303,\n",
       "        1.80532546, 2.31889506, 2.33852495, 1.9021423 , 2.15557547,\n",
       "        2.85888215, 2.76962721, 2.47992952, 2.51089116, 2.75762819,\n",
       "        0.        , 4.60274362, 2.27564382, 1.80077639, 3.0483445 ,\n",
       "        4.35475045, 4.19201006, 4.32256056, 2.57228583, 3.65152259],\n",
       "       [4.53060713, 5.61115206, 5.78579577, 5.71054069, 3.44070659,\n",
       "        5.845894  , 5.85914649, 4.58786972, 4.71316965, 6.10531952,\n",
       "        6.46884262, 6.28160182, 5.17855075, 3.97927672, 2.86185049,\n",
       "        4.60274362, 0.        , 4.72010622, 4.85836993, 4.04226892,\n",
       "        3.35375276, 5.64023419, 4.81610227, 4.48457125, 2.53526032],\n",
       "       [2.55189241, 1.94059619, 2.83413483, 1.98807518, 2.55607104,\n",
       "        2.52896819, 1.89407985, 1.7719952 , 1.69080486, 2.57593278,\n",
       "        2.86321161, 2.46019847, 2.18540434, 2.41241642, 2.67645184,\n",
       "        2.27564382, 4.72010622, 0.        , 1.46194896, 3.10644231,\n",
       "        3.73707932, 4.19562329, 4.01484978, 2.12541144, 3.45117955],\n",
       "       [2.38405222, 2.31923516, 2.35659073, 2.00529452, 2.4225358 ,\n",
       "        2.37901734, 1.80042169, 2.37354751, 1.58961624, 2.6689337 ,\n",
       "        2.96126085, 2.36607444, 2.14021226, 2.53639305, 2.59226331,\n",
       "        1.80077639, 4.85836993, 1.46194896, 0.        , 2.48037537,\n",
       "        3.96395149, 4.18885363, 4.22265975, 2.05898976, 3.68773925],\n",
       "       [4.54995018, 3.7465587 , 3.7213022 , 3.61998805, 2.55294467,\n",
       "        3.91780199, 3.66741108, 3.73261453, 2.67984836, 4.41587277,\n",
       "        4.85849824, 3.81167772, 3.89008692, 3.61594564, 2.97753829,\n",
       "        3.0483445 , 4.04226892, 3.10644231, 2.48037537, 0.        ,\n",
       "        2.91476209, 4.91551903, 4.66484767, 3.11169599, 3.14329928],\n",
       "       [4.92487018, 5.22903221, 5.49904827, 5.15388887, 3.34448882,\n",
       "        5.43000073, 4.82681288, 4.65834003, 3.98118698, 5.75135744,\n",
       "        6.17427612, 5.70362428, 4.83708098, 3.06120394, 3.84437606,\n",
       "        4.35475045, 3.35375276, 3.73707932, 3.96395149, 2.91476209,\n",
       "        0.        , 3.59563767, 3.53944237, 2.89355099, 2.52173267],\n",
       "       [5.02535699, 5.11299009, 5.1319327 , 4.96840533, 3.92867952,\n",
       "        5.08157785, 4.74937021, 4.69140979, 3.75696449, 5.34610657,\n",
       "        5.58981953, 5.41302524, 4.1387905 , 2.62111697, 5.07742377,\n",
       "        4.19201006, 5.64023419, 4.19562329, 4.18885363, 4.91551903,\n",
       "        3.59563767, 0.        , 3.08649528, 2.69752974, 4.32153559],\n",
       "       [4.34499544, 4.91248138, 4.08187083, 5.26402925, 3.45158045,\n",
       "        5.38670027, 4.784221  , 4.19577073, 3.50633347, 5.56163786,\n",
       "        6.01469345, 5.67290877, 3.76838649, 2.77096717, 4.01357743,\n",
       "        4.32256056, 4.81610227, 4.01484978, 4.22265975, 4.66484767,\n",
       "        3.53944237, 3.08649528, 0.        , 2.87230459, 3.42160651],\n",
       "       [3.41165627, 3.35513206, 3.41134729, 3.09486398, 2.38642706,\n",
       "        3.42068878, 2.75333249, 3.06744934, 2.25224204, 3.64488037,\n",
       "        4.14273327, 3.43060074, 2.78545831, 1.38591266, 3.28375677,\n",
       "        2.57228583, 4.48457125, 2.12541144, 2.05898976, 3.11169599,\n",
       "        2.89355099, 2.69752974, 2.87230459, 0.        , 2.62240722],\n",
       "       [3.84182357, 4.65245821, 4.84289023, 4.78761584, 2.48838937,\n",
       "        4.86265268, 4.39665075, 3.46921998, 3.40722991, 4.90298498,\n",
       "        5.62138364, 5.27425657, 4.31348002, 2.72583084, 2.20057762,\n",
       "        3.65152259, 2.53526032, 3.45117955, 3.68773925, 3.14329928,\n",
       "        2.52173267, 4.32153559, 3.42160651, 2.62240722, 0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(w_distances1.shape)\n",
    "w_distances1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with K-Means\n",
    "\n",
    "Clustering with K-Means achieves somewhat reasonable results when restricting to two clusters and they roughly fall into the categories of \"deep learning\" and \"not deep learning\", but notice the method is not perfect at capturing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient for KMeans: 0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amelieschreiber/anaconda3/envs/env_1/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Set the number of clusters you want to divide your data into\n",
    "n_clusters = 2\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(w_distances1)\n",
    "labels_kmeans = kmeans.labels_\n",
    "print(\"Silhouette Coefficient for KMeans: %0.3f\"\n",
    "      % silhouette_score(w_distances1, labels_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 17, 18,\n",
       "        23]),\n",
       " 1: array([14, 16, 19, 20, 21, 22, 24])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_kmeans = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "clusters_kmeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding More Clusters\n",
    "\n",
    "Notice how adding more clusters only worsens the performance of K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient for KMeans: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amelieschreiber/anaconda3/envs/env_1/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Set the number of clusters you want to divide your data into\n",
    "n_clusters = 8\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(w_distances1)\n",
    "labels_kmeans = kmeans.labels_\n",
    "print(\"Silhouette Coefficient for KMeans: %0.3f\"\n",
    "      % silhouette_score(w_distances1, labels_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 0,  2, 12]),\n",
       " 1: array([16, 20, 24]),\n",
       " 2: array([5, 6, 9]),\n",
       " 3: array([14, 19]),\n",
       " 4: array([ 4, 13, 23]),\n",
       " 5: array([21, 22]),\n",
       " 6: array([ 1,  3, 10, 11]),\n",
       " 7: array([ 7,  8, 15, 17, 18])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_kmeans = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "clusters_kmeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering\n",
    "\n",
    "Agglomerative clustering isn't really any better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient for Agglomerative Clustering: 0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amelieschreiber/anaconda3/envs/env_1/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:983: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "\n",
    "# Agglomerative Clustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='average').fit(w_distances1)\n",
    "labels_agg = agg_clustering.labels_\n",
    "print(\"Silhouette Coefficient for Agglomerative Clustering: %0.3f\"\n",
    "      % silhouette_score(w_distances1, labels_agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 23, 24]),\n",
       " 1: array([21, 22])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_agg = {i: np.where(agg_clustering.labels_ == i)[0] for i in range(agg_clustering.n_clusters_)}\n",
    "clusters_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient for Agglomerative Clustering: 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amelieschreiber/anaconda3/envs/env_1/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:983: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 8\n",
    "\n",
    "# Agglomerative Clustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='average').fit(w_distances1)\n",
    "labels_agg = agg_clustering.labels_\n",
    "print(\"Silhouette Coefficient for Agglomerative Clustering: %0.3f\"\n",
    "      % silhouette_score(w_distances1, labels_agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 4, 13, 14, 23, 24]),\n",
       " 1: array([ 1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 15, 17, 18]),\n",
       " 2: array([22]),\n",
       " 3: array([19]),\n",
       " 4: array([20]),\n",
       " 5: array([21]),\n",
       " 6: array([0]),\n",
       " 7: array([16])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_agg = {i: np.where(agg_clustering.labels_ == i)[0] for i in range(agg_clustering.n_clusters_)}\n",
    "clusters_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent Homology of Persistent Homology for DBSCAN\n",
    "\n",
    "Now, we run persistent homology *a second time* on the distance matrix `w_distances1` to inform a DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Persistence diagram'}, xlabel='Birth', ylabel='Death'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "\n",
    "# The max_edge_length parameter should be chosen based on the scale of distances in your dataset.\n",
    "# It is the maximum edge length for the Rips complex.\n",
    "max_edge_length = np.max(w_distances1)\n",
    "\n",
    "# Initialize a Rips complex from the distance matrix.\n",
    "rips_complex = gd.RipsComplex(distance_matrix=w_distances1, max_edge_length=max_edge_length)\n",
    "\n",
    "# Initialize a simplex tree from the Rips complex.\n",
    "simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "\n",
    "# Compute persistence diagram of the simplex tree.\n",
    "diag2 = simplex_tree.persistence()\n",
    "\n",
    "# Plot the persistence diagram\n",
    "gd.plot_persistence_diagram(diag2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the persistence diagram to inform your choice of parameters for DBSCAN. In particular, the `eps` parameter of DBSCAN is similar to the persistence of homological features: increasing `eps` will cause more points to be included in the same cluster, similar to how increasing the persistence will cause more features to be included in the homology. Thus, you might choose `eps` to be slightly larger than the largest persistence of a significant feature. However, keep in mind that this is just a heuristic and may not always give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient for DBSCAN: 0.056\n"
     ]
    }
   ],
   "source": [
    "# DBSCAN \n",
    "# Note: For DBSCAN, you don't need to specify the number of clusters\n",
    "dbscan = DBSCAN(metric=\"precomputed\", eps=1.950, min_samples=1).fit(w_distances1)\n",
    "labels_dbscan = dbscan.labels_\n",
    "print(\"Silhouette Coefficient for DBSCAN: %0.3f\"\n",
    "      % silhouette_score(w_distances1, labels_dbscan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: [0]\n",
      "Cluster 1: [ 1  3  5  6  7  8  9 10 11 12 15 17 18]\n",
      "Cluster 2: [2]\n",
      "Cluster 3: [ 4 13 14 23]\n",
      "Cluster 4: [16]\n",
      "Cluster 5: [19]\n",
      "Cluster 6: [20]\n",
      "Cluster 7: [21]\n",
      "Cluster 8: [22]\n",
      "Cluster 9: [24]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Get unique labels (clusters) and ignore noise if present.\n",
    "clusters = set(labels_dbscan)\n",
    "if -1 in clusters:\n",
    "    clusters.remove(-1)\n",
    "\n",
    "# Print the clusters and their members\n",
    "for cluster_id in clusters:\n",
    "    members = np.where(labels_dbscan == cluster_id)[0]  # Indices of the members in this cluster\n",
    "    print(f'Cluster {cluster_id}: {members}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `[4]` is a bit of an outlier in terms of content, speaking more about healthcare than deep learning. Notice also that each of `text_1[18], text_1[19], text_1[20], text_1[21], text_1[22], text_1[23], text_1[24]` should probably be in their own clusters. So, this method, while better than the others, is not perfect either. One way we might alleviate this is by performing this analysis for each head in each layer of the model. Then, we have several options. We could compute the Fréchet mean diagram of each `text_1[i]` across all heads of the model, and then run the above analysis on the Fréchet mean diagrams. We might also look at the clusters formed across all of the attention heads in the above way and use a method for choosing the best ones, such as simply choosing the one with the bext silhouette coefficient. There are of course more advanced options as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
